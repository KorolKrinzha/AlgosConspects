## 1. Статический массив. Динамический массив, среднее время добавления элемента.

### Статический массив

**Определение** Это структура данных, которая хранит элементы
одного типа в последовательности _с фиксированным размером_
Каждый элемент массива имеет уникальный индекс (начиная с 0) и хранит значение заданного типа.

**Создание массива** Для создания статического массива необходимо указать его размер,
который определяется на этапе компиляции программы.
Размер статического массива не может быть изменен в процессе выполнения.

Для создания статического массива в Java необходимо указать его тип, имя и размер

```java
int[] arr = new int[10]; // создание массива на 10 элементов типа int
```

**Работа со статическим массивом** Для доступа к элементам массива используется индекс, который указывает на позицию элемента в массиве. Индексы в Java начинаются с нуля.

```java
// Работаем с уже созданным массивом
arr[0] = 1; // назначили первый элемент массива
arr[1] = 2; // назначили второй элемент массива
arr[0] = 10; // переписали первый элемент массива
```

**Операции с массивами** Создание, удаление, модификация (добавление/удаление/переписывание) элементов, итерация по элементам, сортировка, копирование, поиск элемента

### Динамический массив

**Чем отличается от статического** Размер массива может меняться по ходе своей работы (то есть динамически)

**Реализация** В языке Java динамический массив представлен классом ArrayList

Как работает ArrayList под капотом?

- При создании создается массив фиксированного размера
- При добавлении нового элемента проверяем, заполнен ли массив
- Если не заполнен, добавляем элемент
- Если заполнен, создается новый массив большего размера (в два раза больше) и копируются все элементы из старого массива в новый. Добавляем элемент в новый массив

Для удаления элемента из динамического массива достаточно просто удалить ссылку на элемент из массива и перераспределить индексы оставшихся элементов, чтобы заполнить создавшуюся пустую ячейку. При этом не происходит перевыделения памяти, как в случае добавления элемента в конец массива.

### Среднее время добавление элемента

Сложность добавления элемента в динамический массив зависит от того, насколько заполнен данный массив.
Существуют две ситуации

1. В массиве есть свободное место после последнего элемента за O(1)
2. Массив заполнен и нужно выделить новый участок памяти O(n), где n - количество элементов в массиве. Это связано с тем, что потребуется копирование всех элементов в новый участок памяти большего размера.

Так как второй случай происходит довольно редко, амортизационная сложность операции добавления элемента в динамический массив обычно составляет O(1), то есть постоянное время.

## 2. Односвязный список, двусвязный список. Псевдокод добавления и удаления.

### Односвязный список

**Определение** Односвязный список - это структура данных, состоящая из узлов (Node), каждый из которых содержит данные и ссылку на следующий узел.

**Реализация узла на джаве**

```java
class Node<T> {
    public T value; // значение данного узла
    public Node next; // ссылка на следующий
}
```

**Иллюстрация**

```
10 -> 20 -> 25 -> 30 -> 40 -> null

10 - tail
40 - tail
```

**Особенности**

Плюсы

- Возможность динамического изменения размера списка
- Не требуется непрерывной области памяти для хранения списка (узлы располагаются в памяти не последовательно, а в произвольных местах, а узлы связываются между собой посредством ссылок)

Минусы

- Для доступа к элементу по индексу требуется выполнить n шагов, где n - номер элемента в списке
- Расходует больше памяти, чем массивы, из-за необходимости хранить ссылки на следующие элементы

**Временная сложность**

- Добавление элемента в начало O(1)
- Обращение к HEAD O(1)
- Добавление элемента в конец O(n) (так как необходимо пройти весь список до его конца)
- Модификация элемента внутри списка O(n) (так как необходимо пройти весь список до нужного элемента)

### Двусвязный список

Теперь мы добавим к каждому узлу поле previous - ссылку на предыдущий элемент. Получится двусвязный список.

**Определение**
Двусвязный список — это структура данных, которая состоит из узлов, каждый из которых содержит ключ и ссылки на предыдущий и следующий узлы.

**Реализация узла на джаве**

```java
class Node<T> {
    public T value; // значение данного узла
    public Node next; // ссылка на следующий узел
    public Node prev; // ссылка на предыдущий узел
}
```

**Иллюстрация**

```
null <- 10 <--> 20 <--> 30 <--> 40 ->  null

10 - head
40 - tail
```

**Особенности**

Плюсы двусвязного списка

Плюсы

- Быстрое добавление и удаление элементов с начала и конца списка
- Доступ к элементу по индексу имеет лучшую производительность по сравнению с односвязным списком

Минусы

- Занимает больше памяти по сравнению с односвязным списком, так как каждый элемент имеет две ссылки на соседние элементы.
- Медленный доступ к элементам по индексу по сравнению с массивом.
- Требует дополнительных операций при вставке или удалении элементов, так как необходимо обновлять две ссылки на соседние элементы.

**Временная сложность**

- Добавление элемента в начало O(1)
- Обращение к HEAD/TAIL O(1)
- Добавление элемента в конец O(1)
- Модификация элемента внутри списка O(n) (так как необходимо пройти весь список до нужного элемента)
- Обращение к элементу внутри списка O(n) (так как необходимо пройти весь список до нужного элемента)

### Псевдокод добавления и удаления

Расскажу про добавление и удаление на двусвязном списке. Он сложнее чем на односвязном, поэтому если мы сделаем правильно процедуры с двусторонним, то с односторонним сделаем по аналогии.

**Добавление**

Добавлять можем по-разному. Можем добавить либо с головы/хвоста, либо по "индексу" справа и слева

Рассмотрим второй случай. Пусть у нас будет следующий список

```
null <- 10 <--> 20 <--> 40 ->  null
```

Между 20 и 40 необходимо вставить элемент с ключом 30.
Алгоритм следующий

- Создадим объект newnode класса Node, ссылки на prev и next
  будут содержать объекты с ключом 20 и 40 относительно
- Пройдемся по массиву, пока не найдем ключи 20 или 40
- Перепишем их ссылки на только что созданный объект newnode

```java

// добавим конструктор
class Node<T> {
    public int value;
    public Node next;
    public Node prev;

    public Node(int value, Node prev, Node next) {
        this.value = value;
        this.prev = prev;
        this.next = next;
    }
}


public void insertNode(Node prevNode, Node nextNode, int newValue) {
    Node<T> newNode = new Node(newValue, prevNode, nextNode);

    // Мы получили ссылки на  переписываем их
    prevNode.next = newNode;
    nextNode.prev = newNode;

}
```

А найдем мы эти объекты, просто пройдясь по списку от хвоста или головы

**Удаление**

Поступаем аналогично добавлению

```java
public void deleteNode(Node nodeToDelete):
    // если такого нет, заканчиваем работу
    if nodeToDelete == null:
        return

    // переназначаем соседей
    if nodeToDelete.prev != null:
        nodeToDelete.prev.next = nodeToDelete.next
    else:
        head = nodeToDelete.next

    if nodeToDelete.next != null:
        nodeToDelete.next.prev = nodeToDelete.prev
    else:
        tail = nodeToDelete.prev

    nodeToDelete = null
```

## 3. АТД Стек. Реализация стека на основе дин. массива, на основе списка.

### Стек

**Определение** Стек - это абстрактная структура данных. Стек - упорядоченная коллекция элементов, где доступ к элементам осуществляется только с одного конца, называемого вершиной стека.

**Принцип** FILO - First In Last Out

**Операции**

- push - положить элемент в стек
- pop - достать элемент из стека
- top/front - посмотреть элемент в вершине стека
- size - размер стека
- empty - проверить, пустой ли стек

**Временная сложность**

- push: O(1)
  (если реализациия на динамическом массиве, то O(n) в худшем случае)
- pop: O(1)
- top: O(1)
- size: O(1)
- empty: O(1)

## Реализация стека на основе динамического массива

**Пример работы стека**

1. До начала работы: пустой массив из двух элементов
2. Push 1: [1, 0] Size: 1 Capacity: 2
3. Push 2: [1, 2] Size: 2 Capacity: 2
4. Push 3.
   - Создаем новый массив размера в два раза большего предыдущего.
   - Поочередно копируем элементы старого массива в новый: [1, 2, 3, 0] Size: 3 Capacity: 4
5. Pop: [1, 2, 0, 0] Size: 2 Capacity: 4
6. Front: 2
7. Pop [1, 0, 0, 0] Size: 1 Capacity: 4

## Реализация стека на основе списка

Возьмем односвязный список. Он будет использоваться в качестве контейнера для хранения элементов стека.

В такой реализации стека, операция добавления и удаления элемента в стек происходит путем работы с **_первым_** элементом односвязного списка

**Пример работы стека**

1. До начала работы: нет node
2. Push 1: добавили Node с ключом 1 и ссылкой на null. Это наша голова и хвост
3. Push 2: Обратились к хвосту. Переписали ссылку на Node с ключом 2 и ссылкой на 1.
   Это **_новый хвост_**
4. Push 3. Обратились к хвосту. Переписали ее ссылку на Node с ключом 3 и ссылкой на 2.
   Это **_новый хвост_**

```
3 -> 2 -> 1
```

5. Pop:
   Обратимся к хвосту списка. Посмотрим на его next - это новый хвост. Старый хвост удаляем

```
2 -> 1
```

## 4. АТД Очередь и Дек. Реализация на основе списка, оценка времени сложности.

### Очередь

**Определение** Очередь - это структура данных, представляющая собой список элементов, в которой элементы добавляются в конец и удаляются из начала

**Принцип** FIFO - First In First Out

**Операции**

- push - положить элемент в очередь
- pop - достать первый элемент очереди
- front - посмотреть элемент в начале очереди
- size - размер очереди
- empty - проверить, является ли очередь пустой

### Реализация очереди на основе списка

Очередь реализована на массиве. Первый элемент очереди находится в начале массива, а последний - в его конце.

**Пример работы очереди**

1. До начала работы: пустой массив из двух элементов
2. Push 1: [0, 1] Size: 1 Capacity: 2
3. Push 2: [2, 1] Size: 2 Capacity: 2
4. Push 3: [0, 3, 2, 1]
   - Создаем новый массив размера в два раза большего предыдущего.
   - Поочередно копируем элементы старого массива в новый: [0, 0, 2, 1]
   - Добавляем новый элемент: [0, 3, 2, 1]
   - Size: 3 Capacity: 4
5. Pop: [0, 0, 2, 0] Size: 2 Capacity: 4
6. Front: 2

### Оценка времени сложности работы очереди

- push - сложность O(1), но в худшем случае может достигать O(n) из-за необходимости выделения нового массива.
- pop и front также имеют сложность O(1)
- size - O(1)
- empty - O(1)

### Дек aka deque (двусторонняя очередь)

Дек (Double Ended Queue) - это структура данных, которая позволяет добавлять и удалять элементы как в начале, так и в конце очереди.

**Операции**

- push_front - положить элемент в начало очереди
- push_back - положить элемент в конец очереди
- pop_front - достать первый элемент очереди
- pop_back - достать последний элемент очереди
- front - посмотреть элемент в начале очереди
- back - посмотреть элемент в конце очереди
- size - размер очереди

## 5. Бинарный поиск. Задача поиска элемента в отсортированном массиве - постановка задачи, оценка сложности алгоритма.

### Бинарный поиск

**Определение** Бинарный поиск - это алгоритм поиска элемента в отсортированном массиве. Он работает путем деления массива пополам и проверки, находится ли искомый элемент в левой или правой половинах массива. Данный процесс повторяется до тех пор, пока элемент не будет найден или пока не останется элементов для проверки.

**Алгоритм**

1. Два указателя на начало и конец массива L и R
   L - левая граница, на один элемент левее начала массива
   R - правая граница, на один элемент правее конца массива
2. Средний элемент mid = (L+R)/2
3. Если mid == x, то мы нашли x
4. Если x лежит слева от mid, то сдвигаем правую границу R = mid - 1
5. Если x лежит справа от mid, то сдвигаем левую границу L = mid + 1

// TODO узнать, будет ли спрашивать по правосторонний и левосторонний поиск.

### Задача поиска элемента в отсортированном массиве

**Постановка задачи**
Дан упорядоченный массив a длины n и элемент x. Необходимо определить, содержится ли элемент x в массиве a. Если да, то найти индекс первого вхождения элемента x в массиве.

**Решение**
Воспользуемся алгоритмом бинарного поиска. Будем последовательно делить отсортированный массив пополам, пока не найдем нужный элемент.

Сложность решения составляет O(log n), что значительно быстрее, чем простой перебор элементов массива, который имеет сложность O(n).

## 6. Поддержка минимума в стеке и очереди.

Для начала расскажем, что такое "Поддержка минимума". Под поддержкой минимума обычно понимается возможность быстрого получения минимального элемента из структуры данных, без необходимости перебирать все элементы.

### Стек

Для реализации поддержки минимума в стеке можно использовать дополнительный стек, в котором будут храниться минимальные элементы. Каждый раз при добавлении нового элемента в основной стек будем проверять, является ли он новым минимумом, и при необходимости добавлять его в дополнительный стек. При удалении элемента из основного стека будем также проверять, являлся ли он минимальным, и при необходимости удалять его из дополнительного стека.

### Очередь

Для реализации поддержки минимума в очереди можно использовать еще одну очередь. Одна будет очередью для обычных элементов, другая для минимумов

При реализации поддержки минимума в деке с использованием двух очередей каждый элемент хранится в одной из двух очередей в зависимости от того, насколько он меньше текущего минимума. Элементы, которые больше или равны текущему минимуму, хранятся в первой очереди, а элементы, которые меньше текущего минимума, хранятся во второй очереди.
Все элементы во второй очереди остаются в конце этой очереди, и это и есть минимумы.

В обоих случаях операции получения минимального элемента будут иметь временную сложность O(1). Будет достаточно получить верхний элемент из дополнительного стека или начальный элемент из дека.

## 7. Двоичная куча. Описание, построение, добавление элемента, извлечение максимума/минимума

### Описание двоичной кучи

**Определение** Двоичная куча - это структура данных, которая представляет собой ориентированное двоичное дерево. Для каждого узла x дерева соответствующий ему элемент ключ x не меньше (для максимальной кучи) или не больше (для минимальной кучи) ключей его потомков.

То есть у нас есть два типа кучи: максимальная и минимальная в зависимости от того, как элемент будет находиться в корне. Будем рассматривать в примерах максимальную кучу

### Построение

**Алгоритм создания кучи из массива**

1. Начинаем с середины массива, так как все узлы после середины являются листьями.
   Листья по умолчанию удовлетворяют свойству кучи.
2. Для каждого рассматриваемого узла сравним его значение со значениями его дочерних узлов.
   Поменяем местами узел с наибольшим дочерним узлом, если это необходимо для сохранения свойства максимальной/минимальной кучи.
3. Двигаемся вверх по дереву
   и повторяем шаг 2 для каждого узла, пока весь массив не будет удовлетворять свойству кучности.

Сложность: O(n)

**Пример**
Дан массив [13, 11, 7, 5, 6, 12]. Построим из него макс кучу

1. 6//2 - 1 = 2. Это индекс середины массива. Начинаем с элемента индексом 2, с 7
2. Сравниваем 7 с детьми (5,6,12). 12 больше 7, меняем 12 и 7.
   Получили [13, 11, 12, 5, 6, 7]
3. Двигаемся вперед к новому индексу. Сравниваем 11 с детьми (12, 5, 6, 7). Меняем 12 и 11 местами, так как 12 больше [13, 12, 11, 5, 6, 7]
4. Сравниваем 13 с детьми (12,11,5,6,7). 13 больше обоих двух детей, поэтому перестановок нет [13, 12, 11, 5, 6, 7]
5. Построим дерево

```
    13
   /   \
  12   11
 / \    \
 5 6     7
```

## Операции

- Построение кучи из неупорядоченного массива. В этом случае все элементы массива вставляются в кучу по одному с помощью операции вставки.
- Вставка нового элемента в кучу. Новый элемент вставляется в свободное место на дне кучи, а затем происходит перестройка кучи (sift up).
- Удаление максимального (первого) элемента из кучи. На место старого корня вставляется _последний_ (чтобы не нарушить остальные ряды) элемент, после чего происходит перестройка кучи (sift down).
- Получение максимального элемента из кучи. Для этого достаточно прочитать значение элемента в корне кучи.

**Операция sift up**

Новый элемент добавляется на последнее место кучи, а затем сравнивается с его родителем. Если родитель меньше добавленного элемента, то они меняются местами. Этот процесс продолжается до тех пор, пока добавленный элемент не окажется на своем месте.

**Операция sift down**

Последний элемент кучи перемещается на место корня, после чего он сравнивается со своими потомками. Если какой-то потомок больше корня, то они меняются местами. Этот процесс продолжается до тех пор, пока корень не окажется на своем месте.

**Временная сложность**

- Вставка элемента - O(log n)
- Получение максимального элемента - O(1)
- Удаление максимального элемента - O(log n)

## 8. Квадратичные сортировки (пузырьком, вставками, выбором), сортировка с помощью двоичной кучи. Описание алгоритмов, оценка времени работы и дополнительной памяти.

### Сортировка пузырьком

**Определение** Сортировка пузырьком — алгоритм сортировки, в котором сравниваются пары соседних элементов.
Если они стоят в неправильном порядке, то производится их обмен.

**Описание алгоритма**

1. Проходим по всем элементам массива слева направо.
2. Сравниваем каждую пару соседних элементов.
3. Если левый элемент больше правого, меняем их местами.
4. Повторяем шаги 1-3 для всех элементов, кроме последнего.
5. Проходим по массиву снова, но уже до предпоследнего элемента.
6. Повторяем шаги 2-5 до тех пор, пока массив не будет отсортирован.

**Пример работы**

Дан массив: [4, 1, 6, 9, 2]

- Итерация 1
  1. Сравниваем первый и второй элементы. 1 меньше 4, поэтому меняем их местами. [1, 4, 6, 9, 2]
  2. Сравниваем второй и третий элемент. 6 больше 4, не меняем местами. Массив: [1, 4, 6, 9, 2]
  3. 9 больше 6, не меняем местами. Массив: [1, 4, 6, 9, 2]
  4. 9 больше 2, меняем их местами. Массив: [1, 4, 6, 2, 9]
- Итерация 2
  1. 1 меньше 4, поэтому не меняем местами. Массив: [1, 4, 6, 2, 9]
  2. 4 меньше 6, поэтому не меняем местами. Массив: [1, 4, 6, 2, 9]
  3. Сравниваем третий и четвертый элемент. 6 больше 2, поэтому меняем их местами. Массив: [1, 4, 2, 6, 9]
  4. 6 меньше 9, поэтому не меняем местами. Массив: [1, 4, 2, 6, 9]
- Итерация 3
  1. 1 меньше 4, поэтому не меняем местами. Массив: [1, 4, 2, 6, 9]
  2. Сравниваем второй и третий элементы. 4 больше 2, поэтому меняем их местами. Массив: [1, 2, 4, 6, 9]
  3. 4 меньше 6, поэтому не меняем местами. Массив: [1, 2, 4, 6, 9]
  4. 6 меньше 9, поэтому не меняем местами. Массив: [1, 2, 4, 6, 9]

**Модификация алгоритма**

_Условие Айверсона-Тьюринга_ гласит, что если в процессе сортировки не было выполнено ни одной перестановки, то массив уже отсортирован.

То есть на каком-то этапе алгоритма все элементы могут встать на свои места.
Как проверить? Если мы пошли по массиву слева направо и не исправили ни одной инверсии, то массив уже отсортирован.

**Временная сложность** O(n^2)

**Дополнительная память** Не требуется

### Сортировка вставками

**Описание алгоритма**

0. Мысленно разбиваем массив на две части: отсортированную и неотсортированную.
1. Берем первый элемент неотсортированной части и вставляем его в отсортированную часть.
2. Расширяем отсортированную часть на один элемент.
3. Переходим к следующему элементу неотсортированной части, он будет следующим для сортировки. Сравниваем следующий элемент с предыдущим и меняем их местами, если они не отсортированы. Мы только что добавили еще один элемент в отсортированную часть.
4. Повторяем шаги 1-3, пока неотсортированная часть массива не окажется пустой

**Пример работы**

1. [2,5,6,1,9,1,1,10]
2. [2] [5,6,1,9,1,1,10]
3. [2,5] [6,1,9,1,1,10]
4. [2,5,6] [1,9,1,1,10]
5. "Проталкиваем влево" 1 в [2,5,6]
   - [2,5,6,1]
   - [2,5,1,6]
   - [2,1,5,6]
   - [1,2,5,6]
6. [1,2,5,6,9] [1,1,10]
7. "Проталкиваем влево" 1 в [1,2,5,6,9]
   - [1,2,5,6,9,1]
   - [1,2,5,6,1,9]
   - [1,2,5,1,6,9]
   - [1,2,1,5,6,9]
   - [1,1,2,5,6,9]
8. [1,1,2,5,6,9,1,10]
   ...
9. [1,1,1,1,2,5,6,9,10]

**Временная сложность** O(n^2)

В худшем случае при сортировке массива [n,n-1,n-2,...,2,1] мы сделаем n-1 шагов.
Каждый раз будем проталкивать n раз.
Итого n(n-1) или n^2

**Дополнительная память** Не требуется

### Сортировка выбором

**Описание алгоритма**

0. Мысленно разбиваем массив на две части: отсортированную и неотсортированную.
1. Проходим по неотсортированной части массива и ищем минимальный элемент.
2. Если это минимум, то меняем его с первым элементом неотсортированной части. Он должен быть в начале неотсортированной части.
3. Переходим к следующему элементу неотсортированной части, оттуда начинаем поиск минимума. Меняем его с _первым элементом неотсортированной части_. Он должен быть в начале неотсортированной части.
4. Повторяем пока неотсортированная часть не закончится.

**Пример работы**

Дан массив: [4, 1, 6, 9, 2]

1. Минимум 1. [4, 1, 6, 9, 2] -> [1, 4, 6, 9, 2].
2. Минимум 2. [1, 4, 6, 9, 2] -> [1, 2, 6, 9, 4]
3. Минимум 4. [1, 2, 6, 9, 4] -> [1, 2, 4, 9, 6].
4. Минимум 6. [1, 2, 4, 9, 6] -> [1, 2, 4, 6, 9]
5. Массив отсортирован

**Временная сложность** O(n^2)

**Дополнительная память** Не требуется

### Сортировка с помощью двойной кучи

## Сортировка кучей

**Описание алгоритма**

0. Необходимо отсортировать массив A размером n
1. Построим кучу из массива A за O(n)
2. Максимальный элемент находится в корне кучи.
3. "Выкидываем" корень в конец, как бы "в сторонку".
4. Уменьшаем размер кучи на 1.
5. Просеиваем корень кучи вниз, чтобы восстановить свойство кучи.
6. Куча имеет размер n-1.
7. Повторяем шаги 2-6, пока куча не станет пустой.
8. Всего будет сделано n-1 операций SiftDown, каждая операция SiftDown имеет сложность O(log2n)

**Сложность алгоритма** O(nlog2n)

**Дополнительная память** Не требуется

**Недостаток алгоритма**

- неустойчивая сортировка. Например, если в массиве есть два одинаковых элемента, то после сортировки они могут поменяться местами.
- на почти отсортированных массивах работает столько же долго,
  сколько на неотсортированном (для почти отсортированных лучше пузырек).

  ## 9. Сортировка слиянием. Описание алгоритма, оценка времени работы

  ## Сортировка слиянием

**Определение** Сортировка слиянием — алгоритм сортировки, который использует принцип «разделяй и властвуй». Идея заключается в том, чтобы разделить массив на части, отсортировать их рекурсивно, а затем объединить уже отсортированные части в один массив.

**Описание алгоритма**

1. Разделение массива на две части: Массив делится на две части примерно одинакового размера.
   Этот шаг рекурсивно применяется к каждой половине, пока каждая часть не станет _размером в один элемент_.

2. Слияние отсортированных частей:
   Два отсортированных подмассива сливаются в один отсортированный массив (об это чуть позже)

3. Объединение: Отсортированные массивы объединяются до тех пор, пока не будет получен отсортированный массив.

**Пример работы**

0. [15,8,1,3,7,4,20,2,5]
1. Разделим пополам [15,8,1,3] [7,4,20,2,5]
2. Затем половинки еще раз разделим пополам [15,8] [1,3] [7,4] [20,2,5]
3. [15] [8] [1] [3] [7] [4] [20] [2, 5]
4. [15] [8] [1] [3] [7] [4] [20] [2] [5]
5. Сливаем первые половинки

- [15] [8]: [8,15]
- [1] [3]: [1,3]
- [7] [4]: [4,7]
- [20] [2] [5]: [2,5,20]

6. Сливаем получившиеся массивы

- [8,15] [1,3]: [1,3,8,15]
- [4,7] [2,5,20]: [2,4,5,7,20]

7. Сливаем

- [1,3,8,15] [2,4,5,7,20]: [1,2,3,4,5,7,8,15,20]

8. Массив отсортирован

### Оценка времени работы

**Временная сложность** O(nlogn)

- logn раз делаем слияние (каждый раз массив делится на 2 части)
- каждое слияние занимает O(n) времени

### Слияние отсортированных двух массивов

### Слияние 2ух сортированных массивов

**Описание алгоритма**

1. Даны два отсортированных массива с длинами n и m
2. Создаем массив длиной n+m элементов
3. Два указателя, каждый на первый элемент массива
4. Сравниваем элементы на указатели, берем меньший и записываем в новый массив
5. Двигаем указатель на следующий элемент в массиве, из которого мы взяли элемент
6. Повторяем пункты 3-5, пока не закончатся элементы во всех массивах

**Пример работы**

0. Дано два массива [1,3,8,15] [2,4,5,7,20]:
1. Создаем массив [0,0,0,0,0,0,0,0,0]
2. Указатели на 1 и 2. 1 меньше, он идет в новый массив [1,0,0,0,0,0,0,0,0]
3. Указатели на 3 и 2. 2 меньше, идет в новый массив [1,2,0,0,0,0,0,0,0]
4. Указатели на 3 и на 4. 3 меньше, идет в новый массив [1,2,0,3,0,0,0,0,0]
5. ...
6. Массив отсортирован [1,2,3,4,5,7,8,15,20]

_Временная сложность_ O(n)

// TODO узнать, надо ли говорить про алгоритм слияния n отсортированных массивов

## 10. Быстрая сортировка. Описание алгоритма, оценка времени работы в лучшем, среднем и худшем случае.

### Быстрая сортировка

**Определение** Быстрая сортировка — алгоритм сортировки, основанный на принципе «разделяй и властвуй»

**Описание алгоритма**

1. Выбирается элемент, называемый опорным (pivot), из массива.
2. Остальные элементы массива распределяются по двум подмассивам: один содержит элементы, меньшие (или равные) опорного, а другой — бОльшие.
3. Рекурсивно повторяем шаги 1 и 2 для каждого из подмассивов.
4. Последовательно соединяем массивы в один

**Пример работы**

0. Дан массив [15,8,1,3,7,4,20,2,5]
1. Выберем опорный элемент. Для данного примера выберем 7 в качестве опорного элемента.
2. Разобьем массив на две части: элементы меньше и опорного и элементы больше опорного.
   [5, 1, 3, 4, 2] [7] [15, 8, 20]
3. Выберем опорные элементы 4 и 8.
   [1,3,2] [4] [5] [7] [] [8] [15,20]
4. Выберем опорные элементы 2 и 15
   [1][2] [3] [4] [5] [7] [] [8] [] [15] [20]
5. Объединим результаты, чтобы получить отсортированный массив.
6. [1, 2, 3, 4, 5, 7, 8, 15, 20]

### Выбор опорного элемента. Случаи

Перечислим методы выбора опорного элемента:

1. Выбираем всегда первый элемент
2. Выбираем всегда серединный элемент
3. Выбирать среднее по трем элементам: первый, средний, последний
4. Выбирать случайный элемент

Проблема с первым методом в том, что мы можем найти массив, при котором мы будем получать O(n^2) в худшем случае.

Пример: [1,2,3,4,5,6,7,8]

1. [1] [2,3,4,5,6,7,8]
2. [1] [2] [3,4,5,6,7,8]
3. [1] [2] [3] [4,5,6,7,8]
   ...
   суммарно слоев n

Нашли массив, который "ломает" алгоритм. Худший случай O(n^2) происходит когда _массив разбивается в соотношении 1:n-1_

Обычно используют 3 и 4 методы.
Выбор случайного элемента в массиве хорошо работает _в среднем случае_, когда элементы в массиве распределены случайным образом.

**Лучший случай** Если опорный элемент на каждом шаге выбирается таким образом, что _разделение массива происходит на две равные части_, то сложность алгоритма будет O(n log n).

## 11. Поиск k-ой порядковой статистики на основе быстрой сортировки. Оценка времени работы и лучшем, среднем и худшем случае.

## 12. Граф. Хранение графа в памяти: список смежности, матрица смежности (плюсы и минусы). Оценка времени поиска всех соседей, добавление ребра. Оценка расходуемой памяти.

Я представлю 4 способа хранения графа в памяти

### 1. Список ребер

**Описание способа** Каждое ребро - массив. Ребро представлено парой вершин, которые оно соединяет.

**Реализация**
ArrayList<ArrayList<Integer>>

[[u1,v1], [u2,v2], [u3,v4], ..., [ui,vj]]

**Оценка времени**

- Поиск всех соседей вершины O(|E|)
- Добавление ребра O(|1|)

**Память** O(|E|)

**Особенности**

- Плюсы:
  - Экономит память в случае графа с маленьким числом ребер (такой называется разреженным)
  - Легкость добавления новых вершин
- Минусы:
  - Медленный доступ к вершинам графа, так как нужно перебирать все ребра
  - Медленный доступ к соседям вершины, так как нужно перебирать все ребра
  - Неудобен для проверки наличия ребра между двумя вершинами, так как надо обходить массив.
  - Не подходит для задания свойств графа, связанных с вершинами, например, степень вершины

### 2. Список смежности

**Описание способа** Граф представляется в виде списка всех его вершин, каждая из которых связана с другими вершинами, с которыми она имеет ребро. Каждая вершина встречается только один раз в списке в виде ключа, для каждой вершины в массиве указываются её соседи.

**Реализация**

HashMap<ArrayList<Integer>>

v1: [u1, u2, ...], v2: [u5, u7, ...], vi: [...]

**Оценка времени**

- Поиск всех соседей вершины O(deg(v)))
- Добавление ребра O(|1|)

**Память** O(|v|\*|E|)

**Особенности**

- Плюсы:
  - Удобен для работы с алгоритмами обхода графа, так как позволяет быстро получать соседей вершины.
  - Экономит память в случае разреженного графа, так как не хранит информацию о несуществующих ребрах.
- Минусы:
  - Неудобен для проверки наличия ребра между двумя вершинами, так как надо обходить массив.
  - Не подходит для работы со свойствами ребер графа
  - Сложность добавления новых вершин

### 3. Матрица смежности

**Описание способа** В этой реализации граф представляется в виде матрицы, в которой каждый элемент (i, j) показывает наличие ребра между вершинами i и j. Значение элемента может быть булевым (true или false) или числовым, если ребра имеют веса.

**Реализация**

- Взвешанный граф: ArrayList<ArrayList<Integer>> [[0,7,9][7,0,0][9,0,0]]
- Невзвешанный граф ArrayList<ArrayList<Boolean>> [[0,1,1][1,0,0][1,0,0]]

**Оценка времени**

- Поиск всех соседей вершины O(V) V - количество вершин в графе
- Добавление ребра O(1)

**Память** O(|v^2|)

**Особенности**

- Плюсы:
  - Быстрый доступ к смежным вершинам
  - Хорошо подходит для плотных графов
- Минусы:
  - Занимает много памяти
  - Неэффективно для разреженных графов
  - Сложность добавлении и удаления вершин

### 4. Представление через классы как связные списки

**Описание способа** Каждый объект класса представляет вершину графа, и содержит информацию о её метке и списке смежных вершин.

**Реализация**

```java
public class Node<T> {
    public T value;
    public Node<T> neighbors[];
}
```

**Оценка времени**

- Поиск всех соседей: O(deg(v))
- Добавление ребра O(1)

**Память** O(|v|)

**Особенности**

Плюсы:

- Эффективность хранения и обработки графов с большим количеством вершин и рёбер;
- Быстрый доступ к смежным вершинам
  Простота работы с графом при использовании объектов и методов.
  Минусы:
- Неэффективность при поиске кратчайшего пути в графе из-за необходимости обхода связного списка;
- Большое количество дополнительных вычислений при выполнении операций с графом.

## 13. Виды графов. Деревья. Связность. Циклы. Полные графы. Ориентированность.
