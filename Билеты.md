## 1. Статический массив. Динамический массив, среднее время добавления элемента.

### Статический массив

**Определение** Это структура данных, которая хранит элементы
одного типа в последовательности _с фиксированным размером_
Каждый элемент массива имеет уникальный индекс (начиная с 0) и хранит значение заданного типа.

**Создание массива** Для создания статического массива необходимо указать его размер,
который определяется на этапе компиляции программы.
Размер статического массива не может быть изменен в процессе выполнения.

Для создания статического массива в Java необходимо указать его тип, имя и размер

```java
int[] arr = new int[10]; // создание массива на 10 элементов типа int
```

**Работа со статическим массивом** Для доступа к элементам массива используется индекс, который указывает на позицию элемента в массиве. Индексы в Java начинаются с нуля.

```java
// Работаем с уже созданным массивом
arr[0] = 1; // назначили первый элемент массива
arr[1] = 2; // назначили второй элемент массива
arr[0] = 10; // переписали первый элемент массива
```

**Операции с массивами** Создание, удаление, модификация (добавление/удаление/переписывание) элементов, итерация по элементам, сортировка, копирование, поиск элемента

### Динамический массив

**Чем отличается от статического** Размер массива может меняться по ходе своей работы (то есть динамически)

**Реализация** В языке Java динамический массив представлен классом ArrayList

Как работает ArrayList под капотом?

- При создании создается массив фиксированного размера
- При добавлении нового элемента проверяем, заполнен ли массив
- Если не заполнен, добавляем элемент
- Если заполнен, создается новый массив большего размера (в два раза больше) и копируются все элементы из старого массива в новый. Добавляем элемент в новый массив

Для удаления элемента из динамического массива достаточно просто удалить ссылку на элемент из массива и перераспределить индексы оставшихся элементов, чтобы заполнить создавшуюся пустую ячейку. При этом не происходит перевыделения памяти, как в случае добавления элемента в конец массива.

### Среднее время добавление элемента

Сложность добавления элемента в динамический массив зависит от того, насколько заполнен данный массив.
Существуют две ситуации

1. В массиве есть свободное место после последнего элемента за O(1)
2. Массив заполнен и нужно выделить новый участок памяти O(n), где n - количество элементов в массиве. Это связано с тем, что потребуется копирование всех элементов в новый участок памяти большего размера.

Так как второй случай происходит довольно редко, амортизационная сложность операции добавления элемента в динамический массив обычно составляет O(1), то есть постоянное время.

## 2. Односвязный список, двусвязный список. Псевдокод добавления и удаления.

### Односвязный список

**Определение** Односвязный список - это структура данных, состоящая из узлов (Node), каждый из которых содержит данные и ссылку на следующий узел.

**Реализация узла на джаве**

```java
class Node<T> {
    public T value; // значение данного узла
    public Node next; // ссылка на следующий
}
```

**Иллюстрация**

```
10 -> 20 -> 25 -> 30 -> 40 -> null

10 - голова
40 - хвост
```

**Особенности**

Плюсы

- Возможность динамического изменения размера списка
- Не требуется непрерывной области памяти для хранения списка (узлы располагаются в памяти не последовательно, а в произвольных местах, а узлы связываются между собой посредством ссылок)

Минусы

- Для доступа к элементу по индексу требуется выполнить n шагов, где n - номер элемента в списке
- Расходует больше памяти, чем массивы, из-за необходимости хранить ссылки на следующие элементы

**Временная сложность**

- Добавление элемента в начало O(1)
- Обращение к голове O(1)
- Обращение к хвосту O(n) (так как необходимо пройти весь массив)
- Добавление элемента в конец O(n) (так как необходимо пройти весь список до его конца)
- Модификация элемента внутри списка O(n) (так как необходимо пройти весь список до нужного элемента)

### Двусвязный список

Теперь мы добавим к каждому узлу поле previous - ссылку на предыдущий элемент. Получится двусвязный список.

**Определение**
Двусвязный список — это структура данных, которая состоит из узлов, каждый из которых содержит ключ и ссылки на предыдущий и следующий узлы.

**Реализация узла на джаве**

```java
class Node<T> {
    public T value; // значение данного узла
    public Node next; // ссылка на следующий узел
    public Node prev; // ссылка на предыдущий узел
}
```

**Иллюстрация**

```
null <- 10 <--> 20 <--> 30 <--> 40 ->  null

10 - голова
40 - хвост
```

**Особенности**

Плюсы двусвязного списка

Плюсы

- Быстрое добавление и удаление элементов с начала и конца списка
- Доступ к элементу по индексу имеет лучшую производительность по сравнению с односвязным списком

Минусы

- Занимает больше памяти по сравнению с односвязным списком, так как каждый элемент имеет две ссылки на соседние элементы.
- Медленный доступ к элементам по индексу по сравнению с массивом.
- Требует дополнительных операций при вставке или удалении элементов, так как необходимо обновлять две ссылки на соседние элементы.

**Временная сложность**

- Добавление элемента в начало O(1)
- Обращение к HEAD/TAIL O(1)
- Добавление элемента в конец O(1)
- Модификация элемента внутри списка O(n) (так как необходимо пройти весь список до нужного элемента)
- Обращение к элементу внутри списка O(n) (так как необходимо пройти весь список до нужного элемента)

### Псевдокод добавления и удаления

Расскажу про добавление и удаление на двусвязном списке. Он сложнее чем на односвязном, поэтому если мы сделаем правильно процедуры с двусторонним, то с односторонним сделаем по аналогии.

**Добавление**

Добавлять можем по-разному. Можем добавить либо с головы/хвоста, либо по "индексу" справа и слева

Рассмотрим второй случай. Пусть у нас будет следующий список

```
null <- 10 <--> 20 <--> 40 ->  null
```

Между 20 и 40 необходимо вставить элемент с ключом 30.
Алгоритм следующий

- Создадим объект newnode класса Node, ссылки на prev и next
  будут содержать объекты с ключом 20 и 40 соответственно
- Пройдемся по массиву, пока не найдем ключи 20 или 40
- Перепишем их ссылки на только что созданный объект newnode

```java

// добавим конструктор
class Node<T> {
    public int value;
    public Node next;
    public Node prev;

    public Node(int value, Node prev, Node next) {
        this.value = value;
        this.prev = prev;
        this.next = next;
    }
}


public void insertNode(Node prevNode, Node nextNode, int newValue) {
    Node<T> newNode = new Node(newValue, prevNode, nextNode);

    // В метод были поданы ссылки на будущие элементы-соседи newNode
    //  перепишем их ссылки, чтобы они указали на новый элемент
    prevNode.next = newNode;
    nextNode.prev = newNode;

}
```

А найдем мы эти объекты, просто пройдясь по списку от хвоста или головы

**Удаление**

Поступаем аналогично добавлению

```java
public void deleteNode(Node nodeToDelete):
    // если такого нет, заканчиваем работу
    if nodeToDelete == null:
        return

    // переназначаем соседей
    if nodeToDelete.prev != null:
        nodeToDelete.prev.next = nodeToDelete.next
    else:
        head = nodeToDelete.next

    if nodeToDelete.next != null:
        nodeToDelete.next.prev = nodeToDelete.prev
    else:
        tail = nodeToDelete.prev

    nodeToDelete = null
```

## 3. АТД Стек. Реализация стека на основе дин. массива, на основе списка.

### Стек

**Определение** Стек - это абстрактная структура данных. Стек - упорядоченная коллекция элементов, где доступ к элементам осуществляется только с одного конца, называемого вершиной стека.

**Принцип** FILO - First In Last Out

**Операции**

- push - положить элемент в стек
- pop - достать элемент из стека
- top/front - посмотреть элемент в вершине стека
- size - размер стека
- empty - проверить, пустой ли стек

**Временная сложность**

- push: O(1)
  (если реализация на динамическом массиве, то O(n) в худшем случае)
- pop: O(1)
- top: O(1)
- size: O(1)
- empty: O(1)

### Реализация стека на основе динамического массива

**Пример работы стека**

1. До начала работы: пустой массив из двух элементов
2. Push 1: [1, 0] Size: 1 Capacity: 2
3. Push 2: [1, 2] Size: 2 Capacity: 2
4. Push 3.
   - Создаем новый массив размера в два раза большего предыдущего.
   - Поочередно копируем элементы старого массива в новый: [1, 2, 3, 0] Size: 3 Capacity: 4
5. Pop: [1, 2, 0, 0] Size: 2 Capacity: 4
6. Front: 2
7. Pop [1, 0, 0, 0] Size: 1 Capacity: 4

### Реализация стека на основе списка

Возьмем односвязный список. Он будет использоваться в качестве контейнера для хранения элементов стека.

В такой реализации стека, операция добавления и удаления элемента в стек происходит путем работы с **_первым_** элементом односвязного списка

**Пример работы стека**

1. До начала работы: нет node
2. Push 1: добавили Node с ключом 1 и ссылкой на null. Это наша голова и хвост
3. Push 2: Обратились к голове. Переписали ссылку на Node с ключом 2 и ссылкой на 1.
   Это **_новая голова_**
4. Push 3. Обратились к голове. Переписали ее ссылку на Node с ключом 3 и ссылкой на 2.
   Это **_новая голова_**

```
3 -> 2 -> 1

3 - голова
1 - хвост
```

5. Pop:
   Обратимся к голове списка за O(1) (так как у односвязного списка есть ссылка на голову, к ней можно обратиться за константное время). Посмотрим на его next - это новая головва. Старую голову удаляем

```
2 -> 1

2 - голова
1 - хвост
```

## 4. АТД Очередь и Дек. Реализация на основе списка, оценка времени сложности.

### Очередь

**Определение** Очередь - это структура данных, представляющая собой список элементов, в которой элементы добавляются в конец и удаляются из начала

**Принцип** FIFO - First In First Out

**Операции**

- push - положить элемент в очередь
- pop - достать первый элемент очереди
- front - посмотреть элемент в начале очереди
- size - размер очереди
- empty - проверить, является ли очередь пустой

### Реализация очереди на основе списка

Очередь реализована на массиве. Первый элемент очереди находится в начале массива, а последний - в его конце.

**Пример работы очереди**

1. До начала работы: пустой массив из двух элементов
2. Push 1: [0, 1] Size: 1 Capacity: 2
3. Push 2: [2, 1] Size: 2 Capacity: 2
4. Push 3: [0, 3, 2, 1]
   - Создаем новый массив размера в два раза большего предыдущего.
   - Поочередно копируем элементы старого массива в новый: [0, 0, 2, 1]
   - Добавляем новый элемент: [0, 3, 2, 1]
   - Size: 3 Capacity: 4
5. Pop: [0, 0, 2, 0] Size: 2 Capacity: 4
6. Front: 2

### Оценка времени сложности работы очереди

- push - сложность O(1), но в худшем случае может достигать O(n) из-за необходимости выделения нового массива.
- pop и front также имеют сложность O(1)
- size - O(1)
- empty - O(1)

### Дек aka deque (двусторонняя очередь)

Дек (Double Ended Queue) - это структура данных, которая позволяет добавлять и удалять элементы как в начале, так и в конце очереди.

**Операции**

- push_front - положить элемент в начало очереди
- push_back - положить элемент в конец очереди
- pop_front - достать первый элемент очереди
- pop_back - достать последний элемент очереди
- front - посмотреть элемент в начале очереди
- back - посмотреть элемент в конце очереди
- size - размер очереди

## 5. Бинарный поиск. Задача поиска элемента в отсортированном массиве - постановка задачи, оценка сложности алгоритма.

### Бинарный поиск

**Определение** Бинарный поиск - это алгоритм поиска элемента в отсортированном массиве. Он работает путем деления массива пополам и проверки, находится ли искомый элемент в левой или правой половинах массива. Данный процесс повторяется до тех пор, пока элемент не будет найден или пока не останется элементов для проверки.

**Алгоритм**

1. Два указателя на начало и конец массива L и R
   L - левая граница, на один элемент левее начала массива (индекс "-1")
   R - правая граница, на один элемент правее конца массива (индекс n)
2. Средний элемент mid = (L+R)/2
3. Если mid == x, то мы нашли x
4. Если x лежит слева от mid, то сдвигаем правую границу R = mid - 1
5. Если x лежит справа от mid, то сдвигаем левую границу L = mid + 1

// TODO узнать, будет ли спрашивать по правосторонний и левосторонний поиск.

### Задача поиска элемента в отсортированном массиве

**Постановка задачи**
Дан упорядоченный массив a длины n и элемент x. Необходимо определить, содержится ли элемент x в массиве a. Если да, то найти индекс первого вхождения элемента x в массиве.

**Решение**
Воспользуемся алгоритмом бинарного поиска. Будем последовательно делить отсортированный массив пополам, пока не найдем нужный элемент.

Сложность решения составляет O(log n), что значительно быстрее, чем простой перебор элементов массива, который имеет сложность O(n).

## 6. Поддержка минимума в стеке и очереди.

Для начала расскажем, что такое "Поддержка минимума". Под поддержкой минимума обычно понимается возможность быстрого получения минимального элемента из структуры данных, без необходимости перебирать все элементы.

### Стек

Для реализации поддержки минимума в стеке можно использовать дополнительный стек, в котором будут храниться минимальные элементы. Каждый раз при добавлении нового элемента в основной стек будем проверять, является ли он новым минимумом, и при необходимости добавлять его в дополнительный стек. При удалении элемента из основного стека будем также проверять, являлся ли он минимальным, и при необходимости удалять его из дополнительного стека.

### Очередь

Для реализации поддержки минимума в очереди можно использовать еще одну очередь. Одна будет очередью для обычных элементов, другая для минимумов

При реализации поддержки минимума в очереди с использованием двух очередей каждый элемент хранится в одной из двух очередей в зависимости от того, насколько он меньше текущего минимума. Элементы, которые больше или равны текущему минимуму, хранятся в первой очереди, а элементы, которые меньше текущего минимума, хранятся во второй очереди.
Все элементы во второй очереди остаются в конце этой очереди, и это и есть минимумы.

В обоих случаях операции получения минимального элемента будут иметь временную сложность O(1). Будет достаточно получить верхний элемент из дополнительной очереди.

## 7. Двоичная куча. Описание, построение, добавление элемента, извлечение максимума/минимума

### Описание двоичной кучи

**Определение** Двоичная куча - это структура данных, которая представляет собой ориентированное двоичное дерево. Для каждого узла x дерева соответствующий ему элемент ключ x не меньше (для максимальной кучи) или не больше (для минимальной кучи) ключей его потомков.

То есть у нас есть два типа кучи: максимальная и минимальная в зависимости от того, как элемент будет находиться в корне. Будем рассматривать в примерах максимальную кучу

### Построение

**Алгоритм создания кучи из массива**

1. Начинаем с середины массива, так как все узлы после середины являются листьями.
   Листья по умолчанию удовлетворяют свойству кучи.
2. Для каждого рассматриваемого узла сравним его значение со значениями его дочерних узлов.
   Поменяем местами узел с наибольшим дочерним узлом, если это необходимо для сохранения свойства максимальной/минимальной кучи.
3. Двигаемся вверх по дереву
   и повторяем шаг 2 для каждого узла, пока весь массив не будет удовлетворять свойству кучности.

Сложность: O(n)

**Пример**
Дан массив [13, 11, 7, 5, 6, 12]. Построим из него макс кучу

1. 6//2 - 1 = 2. Это индекс середины массива. Начинаем с элемента индексом 2, с 7
2. Сравниваем 7 с детьми (5,6,12). 12 больше 7, меняем 12 и 7.
   Получили [13, 11, 12, 5, 6, 7]
3. Двигаемся вперед к новому индексу. Сравниваем 11 с детьми (12, 5, 6, 7). Меняем 12 и 11 местами, так как 12 больше [13, 12, 11, 5, 6, 7]
4. Сравниваем 13 с детьми (12,11,5,6,7). 13 больше обоих двух детей, поэтому перестановок нет [13, 12, 11, 5, 6, 7]
5. Построим дерево

```
    13
   /   \
  12   11
 / \    \
 5 6     7
```

### Операции

- Построение кучи из неупорядоченного массива. В этом случае все элементы массива вставляются в кучу по одному с помощью операции вставки.
- Вставка нового элемента в кучу. Новый элемент вставляется в свободное место на дне кучи, а затем происходит перестройка кучи (sift up).
- Удаление максимального (первого) элемента из кучи. На место старого корня вставляется _последний_ (чтобы не нарушить остальные ряды) элемент, после чего происходит перестройка кучи (sift down).
- Получение максимального элемента из кучи. Для этого достаточно прочитать значение элемента в корне кучи.

**Операция sift up**

Новый элемент добавляется на последнее место кучи, а затем сравнивается с его родителем. Если родитель меньше добавленного элемента, то они меняются местами. Этот процесс продолжается до тех пор, пока добавленный элемент не окажется на своем месте.

**Операция sift down**

Последний элемент кучи перемещается на место корня, после чего он сравнивается со своими потомками. Если какой-то потомок больше корня, то они меняются местами. Этот процесс продолжается до тех пор, пока корень не окажется на своем месте.

**Временная сложность**

- Вставка элемента - O(log n)
- Получение максимального элемента - O(1)
- Удаление максимального элемента - O(log n)

## 8. Квадратичные сортировки (пузырьком, вставками, выбором), сортировка с помощью двоичной кучи. Описание алгоритмов, оценка времени работы и дополнительной памяти.

### Сортировка пузырьком

**Определение** Сортировка пузырьком — алгоритм сортировки, в котором сравниваются пары соседних элементов.
Если они стоят в неправильном порядке, то производится их обмен.

**Описание алгоритма**

1. Проходим по всем элементам массива слева направо.
2. Сравниваем каждую пару соседних элементов.
3. Если левый элемент больше правого, меняем их местами.
4. Повторяем шаги 1-3 для всех элементов, кроме последнего.
5. Проходим по массиву снова, но уже до предпоследнего элемента.
6. Повторяем шаги 2-5 до тех пор, пока массив не будет отсортирован.

**Пример работы**

Дан массив: [4, 1, 6, 9, 2]

- Итерация 1
  1. Сравниваем первый и второй элементы. 1 меньше 4, поэтому меняем их местами. [1, 4, 6, 9, 2]
  2. Сравниваем второй и третий элемент. 6 больше 4, не меняем местами. Массив: [1, 4, 6, 9, 2]
  3. 9 больше 6, не меняем местами. Массив: [1, 4, 6, 9, 2]
  4. 9 больше 2, меняем их местами. Массив: [1, 4, 6, 2, 9]
- Итерация 2
  1. 1 меньше 4, поэтому не меняем местами. Массив: [1, 4, 6, 2, 9]
  2. 4 меньше 6, поэтому не меняем местами. Массив: [1, 4, 6, 2, 9]
  3. Сравниваем третий и четвертый элемент. 6 больше 2, поэтому меняем их местами. Массив: [1, 4, 2, 6, 9]
  4. 6 меньше 9, поэтому не меняем местами. Массив: [1, 4, 2, 6, 9]
- Итерация 3
  1. 1 меньше 4, поэтому не меняем местами. Массив: [1, 4, 2, 6, 9]
  2. Сравниваем второй и третий элементы. 4 больше 2, поэтому меняем их местами. Массив: [1, 2, 4, 6, 9]
  3. 4 меньше 6, поэтому не меняем местами. Массив: [1, 2, 4, 6, 9]
  4. 6 меньше 9, поэтому не меняем местами. Массив: [1, 2, 4, 6, 9]

**Модификация алгоритма**

_Условие Айверсона-Тьюринга_ гласит, что если в процессе сортировки не было выполнено ни одной перестановки, то массив уже отсортирован.

То есть на каком-то этапе алгоритма все элементы могут встать на свои места.
Как проверить? Если мы пошли по массиву слева направо и не исправили ни одной инверсии, то массив уже отсортирован.

**Временная сложность** O(n^2)

**Дополнительная память** Не требуется

### Сортировка вставками

**Описание алгоритма**

0. Мысленно разбиваем массив на две части: отсортированную и неотсортированную.
1. Берем первый элемент неотсортированной части и вставляем его в отсортированную часть.
2. Расширяем отсортированную часть на один элемент.
3. Переходим к следующему элементу неотсортированной части, он будет следующим для сортировки. Сравниваем следующий элемент с предыдущим и меняем их местами, если они не отсортированы. Мы только что добавили еще один элемент в отсортированную часть.
4. Повторяем шаги 1-3, пока неотсортированная часть массива не окажется пустой

**Пример работы**

1. [2,5,6,1,9,1,1,10]
2. [2] [5,6,1,9,1,1,10]
3. [2,5] [6,1,9,1,1,10]
4. [2,5,6] [1,9,1,1,10]
5. "Проталкиваем влево" 1 в [2,5,6]
   - [2,5,6,1]
   - [2,5,1,6]
   - [2,1,5,6]
   - [1,2,5,6]
6. [1,2,5,6,9] [1,1,10]
7. "Проталкиваем влево" 1 в [1,2,5,6,9]
   - [1,2,5,6,9,1]
   - [1,2,5,6,1,9]
   - [1,2,5,1,6,9]
   - [1,2,1,5,6,9]
   - [1,1,2,5,6,9]
8. [1,1,2,5,6,9,1,10]
   ...
9. [1,1,1,1,2,5,6,9,10]

**Временная сложность** O(n^2)

В худшем случае при сортировке массива [n,n-1,n-2,...,2,1] мы сделаем n-1 шагов.
Каждый раз будем проталкивать n раз.
Итого n(n-1) или n^2

**Дополнительная память** Не требуется

### Сортировка выбором

**Описание алгоритма**

0. Мысленно разбиваем массив на две части: отсортированную и неотсортированную.
1. Проходим по неотсортированной части массива и ищем минимальный элемент.
2. Если это минимум, то меняем его с первым элементом неотсортированной части. Он должен быть в начале неотсортированной части.
3. Переходим к следующему элементу неотсортированной части, оттуда начинаем поиск минимума. Меняем его с _первым элементом неотсортированной части_. Он должен быть в начале неотсортированной части.
4. Повторяем пока неотсортированная часть не закончится.

**Пример работы**

Дан массив: [4, 1, 6, 9, 2]

1. Минимум 1. [4, 1, 6, 9, 2] -> [1, 4, 6, 9, 2].
2. Минимум 2. [1, 4, 6, 9, 2] -> [1, 2, 6, 9, 4]
3. Минимум 4. [1, 2, 6, 9, 4] -> [1, 2, 4, 9, 6].
4. Минимум 6. [1, 2, 4, 9, 6] -> [1, 2, 4, 6, 9]
5. Массив отсортирован

**Временная сложность** O(n^2)

**Дополнительная память** Не требуется

### Сортировка с помощью двоичной кучи

**Описание алгоритма**

0. Необходимо отсортировать массив A размером n
1. Построим кучу из массива A за O(n)
2. Максимальный элемент находится в корне кучи.
3. "Выкидываем" корень в конец, как бы "в сторонку".
4. Уменьшаем размер кучи на 1.
5. Выполняем sift Down.
6. Куча имеет размер n-1.
7. Повторяем шаги 2-6, пока куча не станет пустой.
8. Всего будет сделано n-1 операций Sift Down, каждая операция Sift Down имеет сложность O(log2n)

**Сложность алгоритма** O(nlog2n)

**Дополнительная память** Не требуется

**Недостаток алгоритма**

- неустойчивая сортировка. Например, если в массиве есть два одинаковых элемента, то после сортировки они могут поменяться местами.
- на почти отсортированных массивах работает столько же долго,
  сколько на неотсортированном (для почти отсортированных лучше пузырек).

## 9. Сортировка слиянием. Описание алгоритма, оценка времени работы

### Сортировка слиянием

**Определение** Сортировка слиянием — алгоритм сортировки, который использует принцип «разделяй и властвуй». Идея заключается в том, чтобы разделить массив на части, отсортировать их рекурсивно, а затем объединить уже отсортированные части в один массив.

**Описание алгоритма**

1. Разделение массива на две части: Массив делится на две части примерно одинакового размера.
   Этот шаг рекурсивно применяется к каждой половине, пока каждая часть не станет _размером в один элемент_.

2. Слияние отсортированных частей:
   Два отсортированных подмассива сливаются в один отсортированный массив (об это чуть позже)

3. Объединение: Отсортированные массивы объединяются до тех пор, пока не будет получен отсортированный массив.

**Пример работы**

0. [15,8,1,3,7,4,20,2,5]
1. Разделим пополам [15,8,1,3] [7,4,20,2,5]
2. Затем половинки еще раз разделим пополам [15,8] [1,3] [7,4] [20,2,5]
3. [15] [8] [1] [3] [7] [4] [20] [2, 5]
4. [15] [8] [1] [3] [7] [4] [20] [2] [5]
5. Сливаем первые половинки

- [15] [8]: [8,15]
- [1] [3]: [1,3]
- [7] [4]: [4,7]
- [20] [2] [5]: [2,5,20]

6. Сливаем получившиеся массивы

- [8,15] [1,3]: [1,3,8,15]
- [4,7] [2,5,20]: [2,4,5,7,20]

7. Сливаем

- [1,3,8,15] [2,4,5,7,20]: [1,2,3,4,5,7,8,15,20]

8. Массив отсортирован

### Оценка времени работы

**Временная сложность** O(nlogn)

- logn раз делаем слияние (каждый раз массив делится на 2 части)
- каждое слияние занимает O(n) времени

### Слияние 2ух сортированных массивов

**Описание алгоритма**

1. Даны два отсортированных массива с длинами n и m
2. Создаем массив длиной n+m элементов
3. Два указателя, каждый на первый элемент массива
4. Сравниваем элементы на указатели, берем меньший и записываем в новый массив
5. Двигаем указатель на следующий элемент в массиве, из которого мы взяли элемент
6. Повторяем пункты 3-5, пока не закончатся элементы во всех массивах

**Пример работы**

0. Дано два массива [1,3,8,15] [2,4,5,7,20]:
1. Создаем массив [0,0,0,0,0,0,0,0,0]
2. Указатели на 1 и 2. 1 меньше, он идет в новый массив [1,0,0,0,0,0,0,0,0]
3. Указатели на 3 и 2. 2 меньше, идет в новый массив [1,2,0,0,0,0,0,0,0]
4. Указатели на 3 и на 4. 3 меньше, идет в новый массив [1,2,0,3,0,0,0,0,0]
5. ...
6. Массив отсортирован [1,2,3,4,5,7,8,15,20]

_Временная сложность_ O(n)

// TODO узнать, надо ли говорить про алгоритм слияния n отсортированных массивов

## 10. Быстрая сортировка. Описание алгоритма, оценка времени работы в лучшем, среднем и худшем случае.

### Быстрая сортировка

**Определение** Быстрая сортировка — алгоритм сортировки, основанный на принципе «разделяй и властвуй»

**Описание алгоритма**

1. Выбирается элемент, называемый опорным (pivot), из массива.
2. Остальные элементы массива распределяются по двум подмассивам: один содержит элементы, меньшие (или равные) опорного, а другой — бОльшие.
3. Рекурсивно повторяем шаги 1 и 2 для каждого из подмассивов.
4. Последовательно соединяем массивы в один

**Пример работы**

0. Дан массив [15,8,1,3,7,4,20,2,5]
1. Выберем опорный элемент. Для данного примера выберем 7 в качестве опорного элемента.
2. Разобьем массив на две части: элементы меньше и опорного и элементы больше опорного.
   [5, 1, 3, 4, 2] [7] [15, 8, 20]
3. Выберем опорные элементы 4 и 8.
   [1,3,2] [4] [5] [7] [] [8] [15,20]
4. Выберем опорные элементы 2 и 15
   [1][2] [3] [4] [5] [7] [] [8] [] [15] [20]
5. Объединим результаты, чтобы получить отсортированный массив.
6. [1, 2, 3, 4, 5, 7, 8, 15, 20]

### Оценка времени работы

Операция разделения массива на две части относительно опорного элемента занимает время
O(n). Все операции разделения, проделываемые на одной глубине рекурсии, обрабатывают разные части исходного массива, _размер которого постоянен_, суммарно на каждом уровне рекурсии потребуется также O(n) операций. Следовательно, общая сложность алгоритма определяется лишь количеством разделений, то есть _глубиной рекурсии_. Глубина рекурсии, в свою очередь, зависит от сочетания входных данных и способа определения опорного элемента.

### Выбор опорного элемента. Случаи

Перечислим методы выбора опорного элемента:

1. Выбираем всегда первый элемент
2. Выбираем всегда серединный элемент
3. Выбирать среднее по трем элементам: первый, средний, последний
4. Выбирать случайный элемент

Проблема с первым методом в том, что мы можем найти массив, при котором мы будем получать O(n^2) в худшем случае.

Пример: [1,2,3,4,5,6,7,8]

1. [1] [2,3,4,5,6,7,8]
2. [1] [2] [3,4,5,6,7,8]
3. [1] [2] [3] [4,5,6,7,8]
   ...
   суммарно слоев n

Нашли массив, который "ломает" алгоритм. Худший случай O(n^2) происходит когда _массив разбивается в соотношении 1:n-1_

Обычно используют 3 и 4 методы.
Выбор случайного элемента в массиве хорошо работает _в среднем случае_, когда элементы в массиве распределены случайным образом.

**Лучший случай** Если опорный элемент на каждом шаге выбирается таким образом, что _разделение массива происходит на две равные части_, то сложность алгоритма будет O(n log2n).

**Средний случай** O(n log n)

## 11. Поиск k-ой порядковой статистики на основе быстрой сортировки. Оценка времени работы и лучшем, среднем и худшем случае.

**Задача** Найти k-ый элемент в массиве.

Пример: Найти для массива [2,4,1,6,5,1,4] третью порядковую статистику.

Решение:

1. отсортируем массив [1,1,2,4,4,5,6]
2. Третий элемент это 2
3. Ответ 2.

Как можно решить задачу:

- Сортировкой. Тогда сложность быстрой сортировки составит O(n log n)
- А если нам надо решить за O(n)?

0. Пусть есть массив [2,3,1,4,2,5,3,2,6]. Надо найти 5-ую порядковую статистику.
1. Разобьем на группы: [2,1,2,2] [3,3] [4,5,6]
2. В первой группе первые 4 элемента.
3. Во второй 2 элемента: 5-ый и 6-ой. Значит, продолжаем работать с группой ней, с группой [3,3]
4. Сортируем и получаем [3,3]. 5-ый элемент - 3.
5. Ответ 3.

А если нам надо найти 7-ую порядковую статистику?

1. Разбиваем как и в прошлый раз [2,1,2,2] [3,3] [4,5,6]
2. Закрываем глаза на группы 1 и 2, работаем с [4,5,6]
3. Берем опорный элемент 5, разбили на 3 группы: [4] [5] [6]
4. В группе [4] содержится 7-ой элемент.
   На остальные группы закрываем глаза и получаем ответ

### Оценка времени работы и лучшем, среднем и худшем случае

В лучшем случае, когда массив уже отсортирован, время работы алгоритма составляет O(n), где n - размер массива.

В среднем случае время работы будет O(n log n), так как быстрая сортировка имеет такую же асимптотическую сложность.

В худшем случае, когда все элементы массива одинаковы, время работы также составит O(n^2), но вероятность такого случая крайне мала, поэтому алгоритм в целом на практике работает быстро.

## 12. Граф. Хранение графа в памяти: список смежности, матрица смежности (плюсы и минусы). Оценка времени поиска всех соседей, добавление ребра. Оценка расходуемой памяти.

Я представлю 4 способа хранения графа в памяти

### 1. Список ребер

**Описание способа** Каждое ребро - массив. Ребро представлено парой вершин, которые оно соединяет.

**Реализация**
ArrayList<ArrayList<Integer>>

[[u1,v1], [u2,v2], [u3,v4], ..., [ui,vj]]

**Оценка времени**

- Поиск всех соседей вершины O(|E|)
- Добавление ребра O(|1|)

**Память** O(|E|)

**Особенности**

- Плюсы:
  - Экономит память в случае графа с маленьким числом ребер (такой называется разреженным)
  - Легкость добавления новых вершин
- Минусы:
  - Медленный доступ к вершинам графа, так как нужно перебирать все ребра
  - Медленный доступ к соседям вершины, так как нужно перебирать все ребра
  - Неудобен для проверки наличия ребра между двумя вершинами, так как надо обходить массив.
  - Не подходит для задания свойств графа, связанных с вершинами, например, степень вершины

### 2. Список смежности

**Описание способа** Граф представляется в виде списка всех его вершин, каждая из которых связана с другими вершинами, с которыми она имеет ребро. Каждая вершина встречается только один раз в списке в виде ключа, для каждой вершины в массиве указываются её соседи.

**Реализация**

HashMap<ArrayList<Integer>>

v1: [u1, u2, ...], v2: [u5, u7, ...], vi: [...]

**Оценка времени**

- Поиск всех соседей вершины O(deg(v)))
- Добавление ребра O(|1|)

**Память** O(|v|\*|E|)

**Особенности**

- Плюсы:
  - Удобен для работы с алгоритмами обхода графа, так как позволяет быстро получать соседей вершины.
  - Экономит память в случае разреженного графа, так как не хранит информацию о несуществующих ребрах.
- Минусы:
  - Неудобен для проверки наличия ребра между двумя вершинами, так как надо обходить массив.
  - Не подходит для работы со свойствами ребер графа
  - Сложность добавления новых вершин

### 3. Матрица смежности

**Описание способа** В этой реализации граф представляется в виде матрицы, в которой каждый элемент (i, j) показывает наличие ребра между вершинами i и j. Значение элемента может быть булевым (true или false) или числовым, если ребра имеют веса.

**Реализация**

- Взвешенный граф: ArrayList<ArrayList<Integer>> [[0,7,9][7,0,0][9,0,0]]
- Невзвешенный граф ArrayList<ArrayList<Boolean>> [[0,1,1][1,0,0][1,0,0]]

**Оценка времени**

- Поиск всех соседей вершины O(V) V - количество вершин в графе
- Добавление ребра O(1)

**Память** O(|v^2|)

**Особенности**

- Плюсы:
  - Быстрый доступ к смежным вершинам
  - Хорошо подходит для плотных графов
- Минусы:
  - Занимает много памяти
  - Неэффективно для разреженных графов
  - Сложность добавлении и удаления вершин

### 4. Представление через классы как связные списки

**Описание способа** Каждый объект класса представляет вершину графа, и содержит информацию о её метке и списке смежных вершин.

**Реализация**

```java
public class Node<T> {
    public T value;
    public Node<T> neighbors[];
}
```

```
nodeB <-- nodeA --> nodeC <---> nodeG
  ^
  |
  |
  |
nodeD <---> nodeE ---> nodeF
```

**Оценка времени**

- Поиск всех соседей: O(deg(v))
- Добавление ребра O(1)

**Память** O(|v|)

**Особенности**

Плюсы:

- Эффективность хранения и обработки графов с большим количеством вершин и рёбер;
- Быстрый доступ к смежным вершинам
  Простота работы с графом при использовании объектов и методов.
  Минусы:
- Неэффективность при поиске кратчайшего пути в графе из-за необходимости обхода связного списка;
- Большое количество дополнительных вычислений при выполнении операций с графом.

## 13. Виды графов. Деревья. Связность. Циклы. Полные графы. Ориентированность.

### Виды графов

Графы можно разделить на несколько типов

- Ориентированные (ребра имеют направления)
- Неориентированные (ребра не имеют направления)

- Взвешенные
- Невзвешенные

- Разреженные (количество ребер много меньше, чем количество вершин)
- Плотные (количество ребер много больше, чем количество вершин)

Еще существуют различные виды графов:

- граф-цикл
- граф-путь
- полный граф
- пустой граф
- двудольный граф
- граф-звезда (частный случай двудольного графа)
- булев куб
- деревья

### Связность

**Определение** Граф называется связным, если существует путь между парой вершин. В противном случае граф называется несвязным.

Компонентами связности называются подмножества вершин в несвязном графе, каждое из которых является связным графом, а любые две вершины из разных компонент не связаны ребром.

Следствие: граф, у которого только одна компонента связности, является связным

Ребро графа называется _мостом_, если его удаление приводит к потере
связности.

Вершина графа называется _шарниром_, если ее удаление приводит к потере связности.

### Деревья

Существуют следующие определения дерева, эквивалентные между собой

1. Связный граф без простых циклов
2. Граф такой, что любая пара вершин соединена единственным простым путём
3. Связный граф, в котором |E| = |V| − 1.
4. Минимально связный граф (то есть все ребра мосты)

### Циклы

**Определение** Простым циклом в графе называется путь, начальная и конечная вершины которого совпадают, а все остальные вершины на этом пути различны. Другими словами, это путь, который начинается и заканчивается в одной и той же вершине, и на котором нет повторяющихся вершин, кроме начальной и конечной.

Граф, содержащий циклы, называется циклическим графом, а граф, не содержащий циклов, называется ациклическим графом

### Полный граф

**Определение** Полный граф - граф, содержащий всевозможные ребра.

Число ребер у полного графа:

- неориентированного: n(n-1)/2
- ориентированного: n(n-1)

## 14. Обход графа в ширину. Описание алгоритма, примеры задач, временная сложность.

**Определение** Обход графа в ширину (BFS - Breadth-First Search) - это алгоритм поиска в графе, который ищет все вершины, достижимые из заданной вершины, путем обхода соседних вершин на каждом уровне. Алгоритм BFS начинает поиск из начальной вершины и _движется слоями_ в глубь графа.

### Описание алгоритма

1. Создать FIFO-очередь, которая будет хранить вершины для посещения.
2. Поместить начальную вершину в очередь.
3. Отметить начальную вершину как посещенную.
4. Извлечь первую вершину из очереди
5. Рассмотреть соседей посещенной вершины
6. Для каждой соседней вершины, которая еще не была посещена, поместить ее в очередь. Пометить их как посещенные
7. Повторять шаги 4-6 до тех пор, пока очередь не станет пустой.

// TODO узнать, нужен ли псевдокод

### Временная сложность

Для начала обсудим, как будем хранить граф, так как это повлияет на время. Будем пользоваться списком смежности. Почему? Список смежности обычно лучше подходит для алгоритма BFS, потому что он представляет граф в виде массива списков, где каждый список представляет собой вершину и ее соседей. Это позволяет легко получать доступ к соседям каждой вершины, что необходимо для алгоритма BFS.
Список смежностей лучше матрице смежности, так как в матрице смежности требуется хранить информацию о каждой паре вершин, даже если между ними нет ребра. В списке смежности хранится только информация о соседях каждой вершины

Каждая вершина и каждое ребро посещаются только один раз.
При хранении графа в виде списков смежности,
временная сложность алгоритма составляет O(|V|+|E|)

**Объем памяти** O(|V|), так как V - максимальное число вершин, хранящееся в памяти

### Пример задач

Алгоритм BFS можно использовать для решения различных задач на графах

Приведем примеры таких задач и идеи решения задач

1. Поиск всех компонент связности в неориентированном графе.

   Идея решения: после первого обхода BFS запустить BFS из каждой вершины, которая еще не была посещена. При запуске BFS из каждой новой вершины мы найдем все вершины, которые могут быть достигнуты из этой вершины, и пометим их как посещенные. Будем повторять BFS, пока все вершины не будут посещены. Таким образом, мы найдем все компоненты связности графа.

2. Найти все вершины, достижимые из данной вершины в ориентированном графе.

   Идея решения: запустить BFS из данной вершины и отметить все достигнутые вершины. В конце BFS мы получим все вершины, которые были достигнуты из данной вершины.

3. Нахождение кратчайшего пути между двумя вершинами

   Идея решения: используем алгоритм Дейкстры вместе с BFS

   Шаги алгоритма

   - Чтобы получить кратчайший путь от начала координат до узла в графе, необходимо хранить два элемента для каждого узла: его текущее кратчайшее расстояние и предшествующий узел в кратчайшем пути.
   - Изначально установим все расстояния на бесконечность, а все предшественники сделаем пустым массивом.
   - Установим расстояние начального узла равным нулю
   - Выполним BFS, исследуя граф по одному уровню за раз.
   - Для каждого узла-потомка проверим, меньше ли расстояние от исходного узла до его предшественника плюс длина исследуемого ребра, чем текущее наилучшее расстояние для узла.
   - Если расстояние может быть улучшено, установим новый кратчайший путь и запомним предшественников, через которого этот путь был получен.
   - Когда очередь BFS пуста, выберем узел и пройдем по его предшественникам назад к началу, чтобы получить кратчайший путь.

// TODO перечитать и переварить в голове 3ую задачу

## 15. Обход графа в глубину. Описание алгоритма, примеры задач, временная сложность. Свойство дерева обхода.

**Описание** DFS (Depth-First Search) - это алгоритм обхода графа, который начинает с заданной вершины и проходит по всем ее потомкам _вглубь_, пока не достигнет конечной вершины.

### Описание алгоритма

DFS может быть рекурсивным или итеративным. Опишем итеративный алгоритм. Пусть по временной сложности отличий нет, но рекурсия имеет ряд недостатков, таких как чрезмерное потребление памяти и ограничение по глубине рекурсии (это значит, что глубокие графы нельзя будет обойти рекурсивно)

1. Создайте пустой _стек_ и добавьте в него начальную вершину.
2. Создайте пустой _список_ для хранения посещенных вершин.
3. Пока стек не пустой, извлеките из него вершину и пометьте ее как посещенную.
4. Добавьте вершину в список посещенных вершин.
5. Для каждой непосещенной смежной вершины поместите ее в стек.
6. Повторяйте шаги 3-5, пока не посетите все вершины в графе.

**Пример работы DFS**

Дан граф. Обойдем с помощью DFS. Покажем, как будет меняться стек и список посещенных вершин

```

     1
  /     \
 2      3
/ \ \  / \
4 5 6  7 8
 / \      \
9  10      12


```

stack:

1. [1]
2. [2, 3]
3. [2, 7, 8]
4. [2, 7, 12]
5. [2, 7]
6. [2]
7. [4, 5, 6]
8. [4, 5]
9. [4, 9, 10]
10. [4, 9]
11. [4, 10]
12. [4]
13. []

visited

1. []
2. [1]
3. [1,3]
4. [1,3,8]
5. [1,3,8, 12]
6. [1,3,8, 12, 7]
7. [1,3,8, 12, 7, 2]
8. [1,3,8, 12, 7, 2, 6]
9. [1,3,8, 12, 7, 2, 6, 5]
10. [1,3,8, 12, 7, 2, 6, 5, 10]
11. [1,3,8, 12, 7, 2, 6, 5, 10, 9]
12. [1,3,8, 12, 7, 2, 6, 5, 9, 10, 4]

### Временная сложность

Если граф представлен в виде списков смежности, то время работы DFS составляет O(V + E), где V - количество вершин, а E - количество ребер. Это происходит потому, что каждая вершина и каждое ребро посещаются не более одного раза.

Для оптимального выполнения DFS граф лучше всего представлять в виде списка смежности. Это позволит быстро получать информацию о соседних вершинах и переходить к ним в процессе обхода.

### Примеры задач

- Поиск компонент связности в графе.

Для этого запускаем DFS из каждой вершины, которая еще не была посещена. Все вершины, которые были посещены в одном запуске DFS, образуют одну компоненту связности.

- Поиск цикла в ориентированном графе.

  Про это в следующем билете

- Поиск мостов и точек сочленения в графе

  Про это в следующем билете

## 16. Поиск цикла в графе (ориентированном и неориентированном) при помощи обхода в глубину. Описание алгоритма, оценка по времени и памяти.

### Поиск цикла в ориентированном графе

Алгоритм поиска цикла в ориентированном графе с помощью DFS основан на поиске обратных ребер. **Определение** Обратное ребро - это ребро, которое соединяет вершину с ее предком в дереве обхода в глубину.

Шаги алгоритма:

1. Выбрать начальную вершину и пометить ее как посещенную.
2. Для каждой непосещенной смежной вершины:
   - Запустить рекурсивный обход в глубину для этой вершины.
   - Если в процессе обхода было обнаружено обратное ребро, значит, в графе есть цикл.
   - Если цикл был обнаружен, прервать дальнейший обход.
3. Если цикл не был обнаружен, то все вершины графа были пройдены.

### Поиск цикла в неориентированном графе

**Идея** для любой вершины v верно следующее утверждение: если к вершине v прилегает вершина u, которая уже была посещена и не u не является родителем v, то у графа есть цикл

**Пример**

```
  1
 /  \
1    2
    /  \
    3 - 4
```

Рассмотрим вершины 2, 3 и 4. Двигаемся с 2 последовательно. Сначала мы дойдем до 3, у нее родитель будет 2. У вершины 3 есть один сосед, вершина 4, посетим ее. У вершины 4 родитель 3. У вершиныы 4, помимо 3, есть еще сосед, вершина 2. Она уже является посещенной, но не из вершины 4, а из вершины 1, так как родитель 2 равен вершине 1. Значит, образовался цикл

Упростим идею с родителями и запишем алгоритм

**Работа алгоритма**

1. Выбираем стартовую вершину и помечаем ее как посещенную.
2. Для каждой непосещенной смежной вершины запускаем DFS рекурсивно, передавая текущую вершину в качестве предыдущей.
3. Если в процессе обхода мы встречаем вершину, которая уже помечена как посещенная, и она не является предыдущей вершиной, то мы обнаружили цикл. Возвращаем true.
4. Если мы прошли все смежные вершины и не нашли цикл, то возвращаем false

### Оценка по времени и памяти

**Оценка неориентированного графа**

Временная сложность алгоритма DFS для поиска цикла в неориентированном графе составляет O(V+E), где V - количество вершин, а E - количество ребер графа.

Для алгоритма нам понадобится

- Сам граф, который хранится в памяти в виде списка смежности. Его размерность зависит от количества вершин и ребер в графе.
- Вспомогательный массив visited размером числа вершин в графе.
- Стек вызовов функций DFS. Его размер зависит от глубины рекурсии, то есть от максимальной длины пути в графе.

Общая оценка памяти составляет O(V)

**Оценка ориентированного графа**

Временная сложность алгоритма DFS для поиска цикла в ориентированном графе составляет O(V+E), где V - количество вершин, а E - количество ребер графа.

Основными структурами данных, используемыми в алгоритме, являются стек и массивы.

Общая оценка памяти составляет O(V)

## 17. Поиск мостов в графе. Определение моста. Алгоритм нахождения мостов.

Чтобы найти мосты, необходимо знать, что мы ищем. Поэтому сначала напишем определение мостов

### Определение мостов

Ребро графа называется _мостом_, если его удаление приводит к потере
связности

**Что такое связность**

Граф называется связным, если существует путь между каждой парой вершин в графе. В противном случае граф называется несвязным.

Компонентами связности называются подмножества вершин в несвязном графе, каждое из которых является связным графом, а любые две вершины из разных компонент не связаны ребром.

То есть когда мы удаляем мост, граф "разрывается" на компоненты связности. Из одной компоненты получается две компоненты.

### Поиск мостов в графе

**Постановка задачи** Поиск мостов в графе — это задача определения ребер, которые при удалении из графа увеличивают количество компонент связности.

**Идея решения**

Алгоритм нахождения мостов в графе можно осуществить с помощью модификации поиска в глубину (DFS).

Чтобы выполнить алгоритм, необходимо ввести пару понятий, а вместе с ними данные:

- tin - это массив, в котором для каждой вершины графа хранится время ее первого посещения при проходе алгоритма DFS.

- low - это массив, в котором для каждой вершины графа хранится минимальное время tin[w] среди всех вершин w, которые можно достигнуть из v, не используя обратное ребро (то есть, не попадая в цикл).

Идея состоит в том, чтобы для каждого ребра (u, v) во время DFS вычислить tin[u] и tin[v] при первом посещении вершины u и v соответственно. Затем необходимо определить значение. Если low[v] больше tin[u], то ребро (u, v) является мостом.

**Описание алгоритма**

1. Запустить обход в глубину из любой вершины u графа.
2. Для каждой вершины v посчитать время захода tin[v].
3. При переходе в новую вершину v запустить обход в глубину из этой вершины и установить значение low[v] равным tin[v].
4. Если в ходе обхода в глубину найден вершину w, такую что _tin[w] < low[v]_, то ребро (v, w) является мостом.

**Покажем на рисунке**

```
     a
    / \
   b - f
  /     \
  c      g
 / \     / \
d -  e  h - f
        \   /
          i
```

Массив tin (опустили лишние ребра)

```
     0
    / \
   1 - 5
  /     \
  2      6
 /        \
3 -  4  9  7
         \ /
          8

```

Массив low

```
     0
    / \
   0 - 0
  /     \
  2       6
 / \     / \
2 -  2  6 - 6
        \   /
          6

```

Ребра рассмотрим ребро между вершинами b-c и f-g:

```
  low  tin
1. 2 > 1
2. 6 > 5
```

### Оценка по времени и памяти

Оценка времени работы алгоритма для графа составляет O(|V| + |E|).

## 18. Поиск точек сочленения в графе. Определение точки сочленения. Алгоритм нахождения точек сочленения.

### Определение точки сочленения

Точка сочленения (шарнир) в неориентированном связном графе — это вершина, которая при удалении делает граф несвязным. Иными словами, если удалить точку сочленения, граф распадается на две или более компонент связности.

### Алгоритм нахождения точек сочленения

1. Нумеруем вершины графа в порядке обхода DFS и создаем массивы tin и low.
2. Помечаем начальную вершину как посещенную и проходим по всем ее соседям. Для каждого непосещенного соседа рекурсивно вызываем функцию DFS, увеличивая переменную time (время захода в вершину).
3. Если вершина v имеет хотя бы одного потомка u, для которого low[u] >= tin[v], то v является точкой сочленения.
4. Если у вершины нет потомков u, для которого low[u] >= tin[v], то low[v] принимает значение min(low[v], low[u]), где u - любой потомок v.
5. Если в текущей компоненте связности есть необработанные вершины, переходим к п. 2.
   Алгоритм работает за время O(V+E), где V - число вершин, E - число ребер графа. Оценка памяти - O(V), так как мы используем массивы tin, low и visited размера V.
